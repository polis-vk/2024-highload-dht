## Параметры системы:
* Treshhold bytes = 1 mb
* Размер очереди = 400
* Max heap size = 128 mb
* Тестируем кластер из 4-х нод
* Параметр ack = 3, from = 4
* Количество потоков = 6

## Сравнение с предыдущей реализацией

* GET (-c 250 -t 1 -R 1100)
  ![](./screens/get_cmp.png)
  Видно, что новая реализация по сравнению с предыдущей при 90м персентиле выдает задержку меньше примерно в два раз.
  Однако, в данном эксперименте также видно, что при 99.99м персентиле ситуация получается обратной. 

* PUT (-c 250 -t 1 -R 750)
  ![](./screens/put_cmp.png)
  При 90м, 99м, 99.9м персентилях задержка при новой реализация меньше примерно в два раза. Наблюдает значительное улучшение производительности.

И get и put запросы выдали меньшую задержку, чем ранее, но для get запросов после 99го персентиля замечен тренд резкого увеличения задержки.

## Определим рабочую нагрузку

* GET
  ![](./screens/get.png)
  Видно, что при rps > 1500 задержка начинает расти намного стремительней.
  Так, замечена разница между 99м персентилями при:
  * rps1 = 1100 и rps2 = 1500 : в 2.1 раза;
  * rps2 = 1500 и rps3 = 1800 : в 5.14 раз.

* PUT
  ![](./screens/put.png)
  Разница при между 99м персентилями при:
  * rps1 = 750 и rps2 = 1500 : в 3,7 раза;
  * rps2 = 1500 и rps3 = 1800 : в 16,59 раз.

Таким образом систему целесообразно тестировать для get запросов при rps=1700, а для put при rps=1600.
По сравнению с предыдущей реализацией уровень рабочего rps увеличился для:
  * GET в 1,5 раза;
  * PUT в 2,1 раза.


## Количество потоков в экзекьюторах

![](./visualvm/1.png)
![](./visualvm/2.png)
![](./visualvm/3.png)
Представлена информации работы потоков при rps=1600.
Видно, что наибольшая задействованность наблюдается среди потоков экзекьютора
для оправки запроса на другую ноду внутри кластера (RemoteCall). В свою очередь, визуально видно, что остальные задействованы на порядок меньше.

Основываясь на общем представлении работы системы, было принято решение использовать экзекьюторы со следующими характеристиками:
* Distributor - для распределения задач по CompletableFuture (3 потоков core, 3 потоков максимум);
* Internal - Для обработки ошибок и добавлении результата в сборщик результатов (3 потока);
* Sender - Для отправки ответа (3 потока);
* RemoteCall - Для вызова на удаленную ноду и ожидания результата (6 потока);
* LocalCall - Для локального запроса к dao (3 потока);


## Проведем профилирование

* ALLOC
  * GET
    ![](./screens/img.png)
    ![](./screens/img_1.png)
    * Поскольку решение было переведено на использование java.net.HttpClient, то появились сопутствующие аллокации.
    * Асинхронная отправка методом jdk/internal/net/http/HttpClientFacade.sendAsync занимает 12.6% аллокаций.
    * 20% всех аллокаций происходит внутри метода tryAsyncReceive при получении ответа от ноды кластера.
  * PUT
    ![](./screens/img_6.png)
    ![](./screens/img_7.png)
    * При получении ответа от ноды кластера методом tryAsyncReceive аллокации снизились до 17% по сравнении с get запросом.

* CPU
  * GET
    ![](./screens/img_2.png)
    ![](./screens/img_3.png)
  * PUT
    ![](./screens/img_8.png)
    ![](./screens/img_9.png)
    * Нагрузка действительно распределилась по потокам. Наибольшее количество процессорного времени занимает RemoteCall протоки.
    * LocalCall, Distributor потоки занимают в среднем от 0.5 до 1 проценту процессорного времени.
    * Запись в сокет при отправке запроса на ноду кластера занимает 11-13% процессорного всего времени для GET и PUT.
    * Текущее тестирование выявило, что 25-27% процессорного времени занято методом java/util/concurrent/ThreadPoolExecutor.getTask, получающим и ожидающим задачи для выполнения. Актуально для GET и PUT запросов.

* LOCK
  * GET
    ![](./screens/img_4.png)
    ![](./screens/img_5.png)
  * PUT
    ![](./screens/img_10.png)
    ![](./screens/img_11.png)
    * Основные блокировки происходят на RemoteCall потоках в ожидании получения результата с удаленной ноды.
    * Distributor и Sender потоки по блокировкам занимают примерно по одному проценту всех блокировок.
    * Internal и LocalCall потоки по блокировкам занимают меньше одного процента всех блокировок.

### Итого
Текущая асинхронная реализация действительно показала лучший результат, а именно меньшую задержку при как при get, так и при put запросах.
За счет использования CompletableFuture появилось намного больше используемых потоков, обеспечивающих наилучшую производительность системы.
Значительно возросло количество блокировок.