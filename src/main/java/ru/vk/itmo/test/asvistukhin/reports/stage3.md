## Нагрузочное тестирование
Тестирование проводил на одной машине в одной среде. Сервер и wrk/async запускались рядом.
JVM была прогрета запросами. Тестировал на трех нодах.
Процессор - i7-10510U.

В рамках данного этапа было реализовано шардирование, проанализирован код.

## Наполнение базы данных
Было сгенерировано с помощью WRK 500MB данных.
Изначально данные распределялись неравномерно, так как я использовал алгоритм хэширования SHA-1. Оказалось, что в случае
распределения данных по нодам, данные распределялись не совсем равномерно, на двух нодах примерно (70-30).
Когда заметил такое распределение, решил хэшировать через murmur3, ситуация стала в разы лучше. Каждая SSTable у меня занимает
5MB. 500MB с помощью murmur3 на трех нодах распределились следующим образом:
1. Первая нода - 27 SSTables
2. Вторая нода - 26 SSTables
3. Третья нода - 29 SSTables
Кажется, что распределение получилось довольно-таки равномерным.

Также, изначально был немного поломанный алгоритм выбора ноды, так как не очень правильно понял реализацию. Из-за неправильного
алгоритма в системе были бесконечные циклы передачи ключа. Допустим, при добавлении ключа он бегал между нодами следующим образом:
1 -> 2 -> 3 -> 1 -> 2 -> 3 -> 1... и так до бесконечности.
Эту ошибку исправил, всё заработало как нужно.

### PUT 10000 RPS
WRK отчет. Тестировал одну минуту, в одном потоке и 64 подключения. Точка разладки ~10000 RPS. С добавлением времени теста,
сервер не деградирует. Но если поставить ~15000 RPS, время ответа становится сильно больше.
```
Running 1m test @ http://localhost:8080/v0/entity
  1 threads and 64 connections
  Thread calibration: mean lat.: 20.897ms, rate sampling interval: 103ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    20.64ms   23.49ms 207.36ms   87.14%
    Req/Sec    10.06k     2.38k   20.28k    66.67%
  Latency Distribution (HdrHistogram - Recorded Latency)
 50.000%   13.20ms
 75.000%   28.05ms
 90.000%   50.69ms
 99.000%  111.17ms
 99.900%  157.05ms
 99.990%  187.65ms
 99.999%  201.85ms
100.000%  207.49ms

  Detailed Percentile spectrum:
       Value   Percentile   TotalCount 1/(1-Percentile)

       0.070     0.000000            1         1.00
       1.124     0.100000        49732         1.11
       2.063     0.200000        99366         1.25
       5.927     0.300000       149010         1.43
       9.503     0.400000       198794         1.67
      13.199     0.500000       248451         2.00
      15.359     0.550000       273246         2.22
      17.807     0.600000       298026         2.50
      20.639     0.650000       322947         2.86
      23.935     0.700000       347776         3.33
      28.047     0.750000       372554         4.00
      30.479     0.775000       384977         4.44
      33.183     0.800000       397413         5.00
      36.319     0.825000       409850         5.71
      40.191     0.850000       422257         6.67
      44.863     0.875000       434663         8.00
      47.615     0.887500       440811         8.89
      50.687     0.900000       447022        10.00
      54.175     0.912500       453237        11.43
      58.143     0.925000       459451        13.33
      62.719     0.937500       465636        16.00
      65.375     0.943750       468743        17.78
      68.415     0.950000       471900        20.00
      71.807     0.956250       474991        22.86
      75.903     0.962500       478083        26.67
      80.895     0.968750       481160        32.00
      83.775     0.971875       482710        35.56
      87.039     0.975000       484266        40.00
      90.815     0.978125       485830        45.71
      94.911     0.981250       487370        53.33
      99.711     0.984375       488932        64.00
     102.335     0.985938       489693        71.11
     105.407     0.987500       490475        80.00
     108.991     0.989062       491259        91.43
     112.895     0.990625       492034       106.67
     117.567     0.992188       492808       128.00
     120.127     0.992969       493195       142.22
     123.135     0.993750       493582       160.00
     126.143     0.994531       493962       182.86
     129.407     0.995313       494352       213.33
     133.375     0.996094       494743       256.00
     135.551     0.996484       494937       284.44
     137.983     0.996875       495136       320.00
     140.159     0.997266       495330       365.71
     142.847     0.997656       495518       426.67
     146.047     0.998047       495710       512.00
     147.839     0.998242       495804       568.89
     149.887     0.998437       495903       640.00
     152.191     0.998633       496000       731.43
     154.623     0.998828       496101       853.33
     157.567     0.999023       496198      1024.00
     158.975     0.999121       496245      1137.78
     160.639     0.999219       496292      1280.00
     163.071     0.999316       496339      1462.86
     165.247     0.999414       496386      1706.67
     168.319     0.999512       496437      2048.00
     169.983     0.999561       496461      2275.56
     171.647     0.999609       496483      2560.00
     173.695     0.999658       496508      2925.71
     176.127     0.999707       496532      3413.33
     178.175     0.999756       496556      4096.00
     179.327     0.999780       496568      4551.11
     180.991     0.999805       496581      5120.00
     182.655     0.999829       496593      5851.43
     184.191     0.999854       496605      6826.67
     185.983     0.999878       496617      8192.00
     187.263     0.999890       496623      9102.22
     187.775     0.999902       496630     10240.00
     188.287     0.999915       496636     11702.86
     189.695     0.999927       496641     13653.33
     191.231     0.999939       496647     16384.00
     191.871     0.999945       496650     18204.44
     192.511     0.999951       496653     20480.00
     193.407     0.999957       496656     23405.71
     194.431     0.999963       496659     27306.67
     195.455     0.999969       496662     32768.00
     197.119     0.999973       496664     36408.89
     198.015     0.999976       496665     40960.00
     199.167     0.999979       496667     46811.43
     199.423     0.999982       496668     54613.33
     200.575     0.999985       496670     65536.00
     201.087     0.999986       496671     72817.78
     201.087     0.999988       496671     81920.00
     201.855     0.999989       496672     93622.86
     203.007     0.999991       496673    109226.67
     205.311     0.999992       496674    131072.00
     205.311     0.999993       496674    145635.56
     205.311     0.999994       496674    163840.00
     205.695     0.999995       496675    187245.71
     205.695     0.999995       496675    218453.33
     206.079     0.999996       496676    262144.00
     206.079     0.999997       496676    291271.11
     206.079     0.999997       496676    327680.00
     206.079     0.999997       496676    374491.43
     206.079     0.999998       496676    436906.67
     207.487     0.999998       496677    524288.00
     207.487     1.000000       496677          inf
#[Mean    =       20.644, StdDeviation   =       23.487]
#[Max     =      207.360, Total count    =       496677]
#[Buckets =           27, SubBuckets     =         2048]
----------------------------------------------------------
  598319 requests in 1.00m, 38.23MB read
Requests/sec:   9971.85
Transfer/sec:    652.46KB
```

### async-profiler
#### CPU
Теперь половину времени обработки запроса забирает проксирование на другую ноду. По графикам профилировщика видно, что запрос на вставку
через proxy запрос занимает ~16 раз больше времени (и нужно учитывать, что это ещё и localhost, без физической передачи данных по проводам),
чем при обращении напрямую. И, как и в прошлых этапах, большую часть процессорного времени
съедают операции сервера (парсинг запроса, отправка ответа и т.д.), также добавилось целых 40% времени на запросы к другим нодам. 
А именно, отправка сообщений и создание потоков под запросы. Не знал, что под капотом там создаются потоки, так как операция вроде бы синхронная.
Но видно, что из метода send, вызывается, неожиданно sendAsync. И затем чтение мы ожидаем через CompletableFuture.
https://docs.oracle.com/en%2Fjava%2Fjavase%2F11%2Fdocs%2Fapi%2F%2F/java.net.http/java/net/http/package-summary.html
Оказалось, что и правда так оно работает.
Но в целом, если не учитывать прокси запросы, нагрузка осталась практически такой же, как и была в прошлом этапе.

#### ALLOC
Здесь выделение памяти под прокси запрос заметно выделяется, так как занимает 56% выделенной памяти. Больше всего съедает создание
заголовков для запроса. Также, 28% на потоки чтения запроса. Остальное же не поменялось по сравнению с прошлым этапом.


### GET 10000 RPS
WRK отчет. Тестировал одну минуту, в одном потоке и 64 подключения. Точка разладки ~10000 RPS. С добавлением времени теста,
сервер не деградирует. Но точка разладки очень чувствительна, даже шаг в 1000 RPS поднимает в разы время ответа.
```
Running 1m test @ http://localhost:8080/v0/entity
  1 threads and 64 connections
  Thread calibration: mean lat.: 28.353ms, rate sampling interval: 129ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    27.87ms   29.44ms 274.43ms   86.41%
    Req/Sec    10.04k     1.90k   20.22k    80.74%
  Latency Distribution (HdrHistogram - Recorded Latency)
 50.000%   17.97ms
 75.000%   39.01ms
 90.000%   66.37ms
 99.000%  137.73ms
 99.900%  194.30ms
 99.990%  237.95ms
 99.999%  271.10ms
100.000%  274.69ms

  Detailed Percentile spectrum:
       Value   Percentile   TotalCount 1/(1-Percentile)

       0.058     0.000000            1         1.00
       2.723     0.100000        59680         1.11
       5.339     0.200000       119430         1.25
       8.519     0.300000       179057         1.43
      12.671     0.400000       238750         1.67
      17.967     0.500000       298550         2.00
      21.135     0.550000       328256         2.22
      24.735     0.600000       358142         2.50
      28.799     0.650000       388006         2.86
      33.471     0.700000       417760         3.33
      39.007     0.750000       447749         4.00
      42.143     0.775000       462530         4.44
      45.695     0.800000       477566         5.00
      49.695     0.825000       492375         5.71
      54.431     0.850000       507356         6.67
      59.807     0.875000       522262         8.00
      62.879     0.887500       529692         8.89
      66.367     0.900000       537175        10.00
      70.335     0.912500       544632        11.43
      75.007     0.925000       552109        13.33
      80.511     0.937500       559521        16.00
      83.711     0.943750       563243        17.78
      87.231     0.950000       566992        20.00
      91.327     0.956250       570737        22.86
      95.999     0.962500       574440        26.67
     101.759     0.968750       578146        32.00
     104.895     0.971875       580013        35.56
     108.415     0.975000       581891        40.00
     112.511     0.978125       583742        45.71
     117.503     0.981250       585607        53.33
     123.583     0.984375       587485        64.00
     126.847     0.985938       588407        71.11
     130.559     0.987500       589336        80.00
     134.911     0.989062       590286        91.43
     139.903     0.990625       591204       106.67
     145.407     0.992188       592146       128.00
     148.351     0.992969       592604       142.22
     151.679     0.993750       593070       160.00
     155.519     0.994531       593537       182.86
     159.103     0.995313       593998       213.33
     163.839     0.996094       594481       256.00
     166.271     0.996484       594702       284.44
     169.087     0.996875       594936       320.00
     172.287     0.997266       595170       365.71
     175.743     0.997656       595408       426.67
     179.455     0.998047       595636       512.00
     181.759     0.998242       595750       568.89
     184.447     0.998437       595868       640.00
     187.647     0.998633       595984       731.43
     190.847     0.998828       596097       853.33
     194.687     0.999023       596217      1024.00
     195.967     0.999121       596277      1137.78
     197.887     0.999219       596331      1280.00
     200.063     0.999316       596391      1462.86
     203.007     0.999414       596446      1706.67
     206.719     0.999512       596505      2048.00
     208.895     0.999561       596533      2275.56
     211.967     0.999609       596564      2560.00
     214.783     0.999658       596593      2925.71
     218.623     0.999707       596622      3413.33
     222.719     0.999756       596650      4096.00
     224.511     0.999780       596665      4551.11
     227.071     0.999805       596679      5120.00
     228.991     0.999829       596694      5851.43
     232.191     0.999854       596708      6826.67
     235.647     0.999878       596723      8192.00
     236.927     0.999890       596730      9102.22
     238.079     0.999902       596737     10240.00
     241.535     0.999915       596745     11702.86
     242.943     0.999927       596754     13653.33
     246.143     0.999939       596759     16384.00
     247.423     0.999945       596763     18204.44
     248.575     0.999951       596766     20480.00
     253.055     0.999957       596770     23405.71
     256.127     0.999963       596774     27306.67
     262.143     0.999969       596777     32768.00
     265.983     0.999973       596779     36408.89
     266.495     0.999976       596781     40960.00
     267.519     0.999979       596783     46811.43
     268.031     0.999982       596785     54613.33
     268.543     0.999985       596786     65536.00
     269.055     0.999986       596787     72817.78
     270.335     0.999988       596788     81920.00
     271.103     0.999989       596790     93622.86
     271.103     0.999991       596790    109226.67
     271.871     0.999992       596792    131072.00
     271.871     0.999993       596792    145635.56
     271.871     0.999994       596792    163840.00
     271.871     0.999995       596792    187245.71
     272.127     0.999995       596793    218453.33
     272.127     0.999996       596793    262144.00
     272.127     0.999997       596793    291271.11
     274.431     0.999997       596794    327680.00
     274.431     0.999997       596794    374491.43
     274.431     0.999998       596794    436906.67
     274.431     0.999998       596794    524288.00
     274.431     0.999998       596794    582542.22
     274.687     0.999998       596795    655360.00
     274.687     1.000000       596795          inf
#[Mean    =       27.869, StdDeviation   =       29.443]
#[Max     =      274.432, Total count    =       596795]
#[Buckets =           27, SubBuckets     =         2048]
----------------------------------------------------------
  698435 requests in 1.17m, 78.63MB read
Requests/sec:   9977.39
Transfer/sec:      1.12MB
```
### async-profiler
#### CPU
На чтении прокси запрос съедает всего в 3 раза больше процессорного времени. Прокси запрос занимает 18% процессорного времени, 
а прямой запрос 6%. Связано это с тем, что бинарный поиск по диску - очень дорогая операция. И в этом случае - шардирование даже увеличило производительность, чего не скажешь о вставке.
Связано это с тем, что теперь на каждой ноде количество SSTables в среднем стало меньше в N (количество нод) раз. При этом,
у нас очень сильно выигрывает операция чтения данных, так как нам не нужно перемалывать кучу таблиц в поиске значения.

И опять же, потоки под обработку java.net.http запросов к другим нодам съели 40% времени.
В остальном же, значения такие же как и в прошлом этапе.


#### ALLOC
27% ушло на обработку потоков для чтения ответа другой ноды. Также, 56% теперь ест создание запроса к ноде. И сейчас,
всего-лишь 6% уходит на операцию get с диска (ну, понятно, что из-за того, что теперь сетевые операции съедают в разы больше,
а не потому, что что-то улучшилось с чтением на диске).

Остальное - так же, как и в прошлом этапе.

### Выводы
Если сравнивать с прошлой версией сервера, где у нас не было шардирования - скорость записи заметно ухудшилась, скорость чтения же, наоборот
выросла в два раза. Связано это с тем, что скорость записи - это быстрая операция, сетевые запросы замедляют эту операцию в разы. В моем
случае RPS упал с 40000 до 10000. С чтением же наоборот - это долгая операция, которая перемалывает кучу таблиц в поиске записи. Шардирование
дает здесь повышение производительности, так как поиск по диску и обращение к другой ноде не различаются в порядок по скорости, но
поиск с N SSTables и N/M SSTables (N - количество таблиц, M - количество нод) дает заметные улучшения, даже при бинарном поиске.
Скорее всего, при настоящем сетевом подключении, ситуация будет похуже, но насколько хуже сказать тяжело. Нужно считать, либо
проверять вручную.

Также, чтобы почувствовать настоящую пользу от шардирования - нужно иметь очень нагруженную базу, в которой распределение нагрузки
будет играть роль (возможно, снизить количество пулов соединений, если оно на пике и т.д.).
В случае загруженных 500МБ и 64 прямых подключений, понятно, что шардирование не помогает (кроме операции чтения).

##### Результаты
Посмотреть результаты async-profiler: src/main/java/ru/vk/itmo/test/asvistukhin/reports/async_profiler/lab3
Скрипты для генерации wrk запросов: src/main/java/ru/vk/itmo/test/asvistukhin/reports/wrk_script