## Нагрузочное тестирование
Тестирование проводил на одной машине в одной среде. Сервер и wrk/async запускались рядом.
JVM была прогрета запросами. Тестировал на трех нодах. Запросы шли с ack=2, from=3.
Процессор - i7-10510U.

В рамках данного этапа было реализовано реплицирование, проанализирован код.

## Наполнение базы данных
Было сгенерировано с помощью WRK ~500MB данных.
1. Первая нода - 24 SSTables
2. Вторая нода - 24 SSTables
3. Третья нода - 24 SSTables


### PUT 8000 RPS
WRK отчет. Тестировал одну минуту, в одном потоке и 64 подключения. Точка разладки ~8000 RPS. С добавлением времени теста,
сервер не деградирует. Но если поставить ~12000 RPS, время ответа становится сильно больше.
```
Running 3m test @ http://localhost:8080/v0/entity
  1 threads and 64 connections
  Thread calibration: mean lat.: 31.861ms, rate sampling interval: 226ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     2.43ms    4.50ms 111.81ms   97.88%
    Req/Sec     8.02k   194.31    10.71k    96.53%
  Latency Distribution (HdrHistogram - Recorded Latency)
 50.000%    1.72ms
 75.000%    2.49ms
 90.000%    3.29ms
 99.000%   21.68ms
 99.900%   67.07ms
 99.990%   94.46ms
 99.999%  104.19ms
100.000%  111.87ms
```

### async-profiler
#### CPU
Теперь половину времени обработки запроса забирает проксирование на другую ноду. По графикам профилировщика видно, что запрос на вставку
через proxy запрос занимает ~16 раз больше времени (и нужно учитывать, что это ещё и localhost, без физической передачи данных по проводам),
чем при обращении напрямую. И, как и в прошлых этапах, большую часть процессорного времени
съедают операции сервера (парсинг запроса, отправка ответа и т.д.), также добавилось целых 40% времени на запросы к другим нодам. 
А именно, отправка сообщений и создание потоков под запросы. Не знал, что под капотом там создаются потоки, так как операция вроде бы синхронная.
Но видно, что из метода send, вызывается, неожиданно sendAsync. И затем чтение мы ожидаем через CompletableFuture.
https://docs.oracle.com/en%2Fjava%2Fjavase%2F11%2Fdocs%2Fapi%2F%2F/java.net.http/java/net/http/package-summary.html
Оказалось, что и правда так оно работает.
Но в целом, если не учитывать прокси запросы, нагрузка осталась практически такой же, как и была в прошлом этапе.

#### ALLOC
Здесь выделение памяти под прокси запрос заметно выделяется, так как занимает 56% выделенной памяти. Больше всего съедает создание
заголовков для запроса. Также, 28% на потоки чтения запроса. Остальное же не поменялось по сравнению с прошлым этапом.


### GET 8000 RPS
WRK отчет. Тестировал одну минуту, в одном потоке и 64 подключения. Точка разладки ~8000 RPS. С добавлением времени теста,
сервер не деградирует. Но точка разладки очень чувствительна, даже шаг в 1000 RPS поднимает в разы время ответа.
```
Running 1m test @ http://localhost:8080/v0/entity
  1 threads and 64 connections
  Thread calibration: mean lat.: 17.085ms, rate sampling interval: 123ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     3.55ms   13.11ms 226.18ms   97.34%
    Req/Sec     8.02k   641.34    15.64k    95.66%
  Latency Distribution (HdrHistogram - Recorded Latency)
 50.000%    1.59ms
 75.000%    2.28ms
 90.000%    2.76ms
 99.000%   71.42ms
 99.900%  174.34ms
 99.990%  201.34ms
 99.999%  216.57ms
100.000%  226.30ms

```
### async-profiler
#### CPU
На чтении прокси запрос съедает всего в 3 раза больше процессорного времени. Прокси запрос занимает 18% процессорного времени, 
а прямой запрос 6%. Связано это с тем, что бинарный поиск по диску - очень дорогая операция. И в этом случае - шардирование даже увеличило производительность, чего не скажешь о вставке.
Связано это с тем, что теперь на каждой ноде количество SSTables в среднем стало меньше в N (количество нод) раз. При этом,
у нас очень сильно выигрывает операция чтения данных, так как нам не нужно перемалывать кучу таблиц в поиске значения.

И опять же, потоки под обработку java.net.http запросов к другим нодам съели 40% времени.
В остальном же, значения такие же как и в прошлом этапе.


#### ALLOC
27% ушло на обработку потоков для чтения ответа другой ноды. Также, 56% теперь ест создание запроса к ноде. И сейчас,
всего-лишь 6% уходит на операцию get с диска (ну, понятно, что из-за того, что теперь сетевые операции съедают в разы больше,
а не потому, что что-то улучшилось с чтением на диске).

Остальное - так же, как и в прошлом этапе.

### Выводы
Если сравнивать с прошлой версией сервера, где у нас не было шардирования - скорость записи заметно ухудшилась, скорость чтения же, наоборот
выросла в два раза. Связано это с тем, что скорость записи - это быстрая операция, сетевые запросы замедляют эту операцию в разы. В моем
случае RPS упал с 40000 до 10000. С чтением же наоборот - это долгая операция, которая перемалывает кучу таблиц в поиске записи. Шардирование
дает здесь повышение производительности, так как поиск по диску и обращение к другой ноде не различаются в порядок по скорости, но
поиск с N SSTables и N/M SSTables (N - количество таблиц, M - количество нод) дает заметные улучшения, даже при бинарном поиске.
Скорее всего, при настоящем сетевом подключении, ситуация будет похуже, но насколько хуже сказать тяжело. Нужно считать, либо
проверять вручную.

Также, чтобы почувствовать настоящую пользу от шардирования - нужно иметь очень нагруженную базу, в которой распределение нагрузки
будет играть роль (возможно, снизить количество пулов соединений, если оно на пике и т.д.).
В случае загруженных 500МБ и 64 прямых подключений, понятно, что шардирование не помогает (кроме операции чтения).

##### Результаты
Посмотреть результаты async-profiler: src/main/java/ru/vk/itmo/test/asvistukhin/reports/async_profiler/lab3
Скрипты для генерации wrk запросов: src/main/java/ru/vk/itmo/test/asvistukhin/reports/wrk_script