## Нагрузочное тестирование
Тестирование проводил на одной машине в одной среде. Сервер и wrk/async запускались рядом.
JVM была прогрета запросами. Тестировал на трех нодах. Запросы шли с ack=2, from=3.
Процессор - i7-10510U.

В рамках данного этапа было реализовано реплицирование, проанализирован код.

## Наполнение базы данных
Было сгенерировано с помощью WRK ~500MB данных.
1. Первая нода - 24 SSTables
2. Вторая нода - 24 SSTables
3. Третья нода - 24 SSTables


### PUT 8000 RPS
WRK отчет. Тестировал одну минуту, в одном потоке и 64 подключения. Точка разладки ~8000 RPS. С добавлением времени теста,
сервер не деградирует. Но если поставить ~12000 RPS, время ответа становится сильно больше.
```
Running 3m test @ http://localhost:8080/v0/entity
  1 threads and 64 connections
  Thread calibration: mean lat.: 31.861ms, rate sampling interval: 226ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     2.43ms    4.50ms 111.81ms   97.88%
    Req/Sec     8.02k   194.31    10.71k    96.53%
  Latency Distribution (HdrHistogram - Recorded Latency)
 50.000%    1.72ms
 75.000%    2.49ms
 90.000%    3.29ms
 99.000%   21.68ms
 99.900%   67.07ms
 99.990%   94.46ms
 99.999%  104.19ms
100.000%  111.87ms
```

### async-profiler
#### CPU
Производительность PUT запросов упала ~20%. И видно, что 20% процессорного времени занимает чтение сокета (ожидание ответов от других нод).
Ещё, из-за множества HTTP запросов начал активнее работать GC, он начал есть целых 5.5% процессорного времени (что в два раза больше, чем в предыдущем этапе).
Теперь у нас практически всё процессорное время забирают сетевые операции: чтение/формирование заголовков, ожидание ответа от сокета и так далее.

#### ALLOC
Аллокации практически не изменились. 22% аллокаций занимает локальная вставка, всё остальное - сетевые операции с другими хостами. А именно, формирование и чтение
заголовков, тела ответа и так далее. Также, при каждом новом запросе мы генерируем новый URL к ноде, ведь мы меняем параметры запроса.

### GET 8000 RPS
WRK отчет. Тестировал одну минуту, в одном потоке и 64 подключения. Точка разладки ~8000 RPS. С добавлением времени теста,
сервер не деградирует. Но точка разладки очень чувствительна, даже шаг в 1000 RPS поднимает в разы время ответа.
```
Running 1m test @ http://localhost:8080/v0/entity
  1 threads and 64 connections
  Thread calibration: mean lat.: 17.085ms, rate sampling interval: 123ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     3.55ms   13.11ms 226.18ms   97.34%
    Req/Sec     8.02k   641.34    15.64k    95.66%
  Latency Distribution (HdrHistogram - Recorded Latency)
 50.000%    1.59ms
 75.000%    2.28ms
 90.000%    2.76ms
 99.000%   71.42ms
 99.900%  174.34ms
 99.990%  201.34ms
 99.999%  216.57ms
100.000%  226.30ms

```
### async-profiler
#### CPU
Чтение также просело ~20% по производительности. И снова видно, что в разы выросло использование сетевых операций, что в целом, не странно.
По графику видно, что ~70% сэмплов мы находимся на sys call'ах сетевых операций. Локальная же операция теперь занимает около ~1-2% от занятого
процессорного времени. Также стало видно, что one-nio подсчитывает количество запросов, которые сервер обработал (2.4% времени ушло на инкремент счетчика
выполненных запросов - Server::incRequestsProcessed)
Остальное выглядит примерно так же, как и в прошлом этапе.

#### ALLOC
~90% аллокаций приходится на обработку сетевых операций, и только 5% на локальный get из MemTable/SSTable. В целом, мало что поменялось. 
График выглядит очень похоже, почти все аллокации уходят на формирование/чтение заголовков, тела запроса и так далее.

### Выводы
Реализация репликации привела к существенному увеличению времени, затрачиваемого на сетевые операции. В частности, ожидание ответов от других узлов заняло
около 20% процессорного времени при выполнении PUT и GET запросов. Это указывает на то, что сетевое взаимодействие между нодами является существенной нагрузкой
и может быть узким местом в архитектуре. Увеличение числа HTTP запросов также привело к более активной работе GC, что заняло до 5.5% процессорного времени. 
Это в два раза больше, чем на предыдущем этапе, что может указывать на увеличение объема кратковременных объектов в памяти, требующих сборки. 
С помощью реплицирования мы повысили надежность системы, но ухудшили производительность.

Кажется, что для существенного улучшения производительности можно сжимать данные, так как основная проблема - долгие сетевые операции. Следовательно,
чем меньше данных передаем - тем быстрее выполняем запросы.

##### Результаты
Посмотреть результаты async-profiler: src/main/java/ru/vk/itmo/test/asvistukhin/reports/async_profiler/lab4
Скрипты для генерации wrk запросов: src/main/java/ru/vk/itmo/test/asvistukhin/reports/wrk_script