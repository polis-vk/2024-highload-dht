## Нагрузочное тестирование
Тестирование проводил на одной машине в одной среде. Сервер и wrk/async запускались рядом.
JVM была прогрета запросами. Тестировал на трех нодах. Запросы шли с ack=2, from=3.
Процессор - i7-10510U.

В рамках данного этапа было реализовано асинхронное взаимодействие между нодами.

## Наполнение базы данных
Было сгенерировано с помощью WRK ~500MB данных.
1. Первая нода - 30 SSTables
2. Вторая нода - 30 SSTables
3. Третья нода - 30 SSTables


### PUT 12000 RPS
WRK отчет. Тестировал одну минуту, в одном потоке и 64 подключения. Точка разладки ~8000 RPS. С добавлением времени теста,
сервер не деградирует. Но если поставить ~12000 RPS, время ответа становится сильно больше.
Производительность PUT запросов увеличилась на 30%.
```
Running 1m test @ http://localhost:8080/v0/entity
  1 threads and 64 connections
  Thread calibration: mean lat.: 7.687ms, rate sampling interval: 17ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     4.19ms    5.72ms  78.78ms   92.55%
    Req/Sec    12.32k     1.46k   15.44k    78.29%
  Latency Distribution (HdrHistogram - Recorded Latency)
 50.000%    2.41ms
 75.000%    3.94ms
 90.000%    7.97ms
 99.000%   32.51ms
 99.900%   52.42ms
 99.990%   65.50ms
 99.999%   75.39ms
100.000%   78.85ms
```

### async-profiler
#### CPU
Производительность PUT запросов выросла на ~30%. Использование процессорного времени GC не выросло. Также видно, что меньше процессорного времени
съедает сетевое взаимодействие нод, из-за того, что мы теперь не блокируемся на запросе к серверу.
В остальном всё выглядит также, почти всё процессорное время съедает сетевое взаимодействие.
#### ALLOC
Аллокации убили GC. ~97% аллоков занимает GC, а именно AllocateHeap. Видимо, я не совсем правильно использую CompletableFuture,
и они накапливаются в памяти. Есть подозрение, что в памяти подвисают те фьючеры, которые ответили позже всего, так как дальше они
нигде не обрабатываются.

### GET 10000 RPS
WRK отчет. Тестировал одну минуту, в одном потоке и 64 подключения. Точка разладки ~10000 RPS. С добавлением времени теста,
сервер не деградирует. Но точка разладки очень чувствительна, даже шаг в 1000 RPS поднимает в разы время ответа.
Производительность GET запросов улучшилась на 20%.
```
Running 1m test @ http://localhost:8080/v0/entity
  1 threads and 64 connections
  Thread calibration: mean lat.: 65.018ms, rate sampling interval: 412ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     2.67ms    1.26ms  28.22ms   79.22%
    Req/Sec    10.01k    37.58    10.16k    75.69%
  Latency Distribution (HdrHistogram - Recorded Latency)
 50.000%    2.38ms
 75.000%    3.14ms
 90.000%    4.20ms
 99.000%    7.15ms
 99.900%   10.73ms
 99.990%   16.78ms
 99.999%   24.14ms
100.000%   28.24ms
```
### async-profiler
#### CPU
Чтение выросло на ~20% по производительности. Также заметно то, что сетевые операции начали съедать меньше процессорного времени, если сравнить
по семплам с прошлой работой, как раз и выйдет ~20%.
В остальном, всё выглядит также, как и в прошлом этапе. GC ест 4.5% процессорного времени.

#### ALLOC
Также, как и в случае с PUT запросами, практически вся аллокация (~97%) приходится на GC. Думаю, здесь ситуация аналогична с PUT,
часть CompletableFuture's, а именно те, которые никак не обрабатываются дальше (запросы которые выполнились после прохода порога
ack), остается в памяти и забивает её.

### Выводы
Реализация асинхронного взаимодействия улучшила производительность, для PUT на ~30%, для GET ~20%. Удивительно то, что производительность
вообще повысилась с учетом того, что вся память выжирается на фьючеры. Все запросы приходят с 200-ми кодами, ошибок никаких нет.
Если исправить проблему с фьючерами, думаю, что производительность должна вырасти ещё (на сколько не знаю).

Асинхронное взаимодействие между нодами улучшает производительность, так как мы не блокируем потоки на ожидание ответа, но нужно
понимать, как правильно работать с CompletableFuture, так как тесты проходят, ошибок никаких нет, производительность даже хорошо выросла,
но без проверки через профилировщик можно нарваться на то, что GC жрет память в сумасшедших количествах.

##### Результаты
Посмотреть результаты async-profiler: src/main/java/ru/vk/itmo/test/asvistukhin/reports/async_profiler/lab5
Скрипты для генерации wrk запросов: src/main/java/ru/vk/itmo/test/asvistukhin/reports/wrk_script