# Stage-4

В данном этапе нужно было реализовать реплицирование данных на несколько нод. Проверим, как изменилась производительность
сервера.

#### PUT
[put_75k](profile_wrk%2Fput_75k) - нагрузку прошлого этапа для put с `RPS=75_000` сервер не выдержал.\
[put_50k](profile_wrk%2Fput_50k) - сервер выдержал нагрузку с `RPS=50_000`.
![put_50k.png](profile_png%2Fput_50k.png)

#### GET

[get_55k](profile_wrk%2Fget_55k) - сервер не справляется даже с половиной `RPS` от прошлого этапа.\
[get_40k](profile_wrk%2Fget_40k)  - но хорошо себя показывает даже при долгом запуске с `RPS=40_000`.\
[get_45k](profile_wrk%2Fget_45k) - с такой же нагрузкой сервер тоже справляется, но появляются медленные запросы.
![get_40k.png](profile_png%2Fget_40k.png)

### Аллокации
Get и Put - появились новые аллокации, связанные с обработкой запроса. В частности, для работы с хедерами и выявления самого свежего ответа из множества.
1) аллокации при выборе клиентов
![alloc_getClients.png](profile_png%2Falloc_getClients.png)
2) аллокации при выборе самого свежего ответа
![alloc_responses.png](profile_png%2Falloc_responses.png)

### CPU
По сравнению с предыдущим этапом, заметно возросла доля, занимаемая методом _invokeRemote_, 
так как сейчас для одного и того же ключа мы перенаправляем запрос одновременно на несколько нод.
![cpu_put.png](profile_png%2Fcpu_put.png)

### Lock
Количество блокировок также значительно увеличилось, поскольку на данном этапе мы отправляем запросы на несколько нод, 
которые, в свою очередь, выполняют одну и ту же работу, требующую захвата блокировки. Возможно, 
использование асинхронной обработки запросов помогло бы сократить количество блокировок, но мы рассмотрим это в следующем этапе ;)
![put_lock.png](profile_png%2Fput_lock.png)

### Надёжность
После заполнения данными с `from=2` и `ack=2` (т.е. реплицировании их на 2/3 нод),
я выключил третью ноду и сравнил надёжность системы с прошлым этапом. Получились следующие результаты:
1) stage-3 \
![durability_s3.png](profile_png%2Fdurability_s3.png)
2) stage-4 \
![durability_s4.png](profile_png%2Fdurability_s4.png)

В четвёртом этапе я запускал Get с параметрами `from=2` и `ack=1`. Видно, что сервер смог ответить на все запросы, несмотря на то, что одна
нода была недоступна. С другой стороны, если собирать `ack` со всех доступных нод (при условии, что одна не работает),
то больше, чем половине случаев выдавало `404 NOT_FOUND`. Однако в реальной жизни мы вряд ли хотим получить подтверждение
от всех, поэтому в данном случае нас это не интересует.


#### Вывод
В отличие от предыдущего этапа, где достаточно было получить ответ от одной ноды, теперь мы практически всегда 
(в зависимости от параметров _ack_ и _from_) вынуждены обращаться сразу к нескольким серверам для получения ответа по 
одному и тому же ключу, что существенно снижает производительность нашей системы. С другой же стороны, живучесть
системы сильно возросла и способна отправлять ответы, даже если какая-то её часть недоступна. Я думаю, это оправданный
trade off по двум причинам в реализации ещё есть места, в которых можно добиться ускорения работы.
