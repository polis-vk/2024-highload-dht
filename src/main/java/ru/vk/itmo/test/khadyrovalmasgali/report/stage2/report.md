# Отчёт Stage 2
Specs

8-Core AMD Ryzen 7 4700U

16Gb RAM 2667 MHz

[lua get requests](./scripts/get.lua)

[lua put requests](./scripts/put.lua)

[wrk2 get output](./wrk/get.txt)

[wrk2 put output](./wrk/put.txt)

[get cpu profile](./asprof/get_cpu.html)

[put cpu profile](./asprof/put_cpu.html)

[get lock profile](./asprof/get_lock.html)

[put lock profile](./asprof/put_lock.html)

[get alloc profile](./asprof/get_alloc.html)

[put alloc profile](./asprof/put_alloc.html)

Тестирование проводилось на 8 (по числу ядер) потоках и 64 соединениях.
Для get - запросов предварительно были выгружены на диск ~150 sstable'ов.

Число selector'ов дефолтное, его уменьшение или увеличение привело только
к падению RPS.

В качестве очереди выбрана ArrayBlockingQueue. LinkedQueue дала просадку
перфоманса, DelayQueue не подходит т. к. является unbounded, SynchronousQueue
в принципе не имеет capacity, а PriorityQueue нам не нужна.

### PUT

На 80к RPS (что ровно в 8 раз больше RPS'a, который приложение выдерживало
на первом этапе) получились такие результаты:

| Percentile | time    |
|------------|---------|
| 50.000%    | 1.44ms  |
| 75.000%    | 2.27ms  |
| 90.000%    | 5.49ms  |
| 99.000%    | 22.40ms |
| 99.900%    | 36.51ms |
| 99.990%    | 44.70ms |
| 99.999%    | 49.66ms |
| 100.000%   | 51.58ms |

Деградация на трех девятках довольно заметная, поэтому тестирование
проводилось на 70к RPS (полный вывод прикреплен).

Судя по профилям, работа по тредам была распределна довольно равномерно,
что хорошо.

Сравним с предыдущим этапом: вывод для 25к RPS

| Percentile | time     |
|------------|----------|
| 50.000%    | 599.55ms |
| 75.000%    | 804.35ms |
| 90.000%    | 956.41ms |
| 99.000%    | 1.30s    |
| 99.900%    | 1.60s    |
| 99.990%    | 1.61s    |
| 99.999%    | 1.62s    |
| 100.000%   | 1.62s    |

Сервис уже умирает.

### GET

65k RPS

| Percentile | time     |
|------------|----------|
| 50.000%    | 4.58ms   |
| 75.000%    | 10.26ms  |
| 90.000%    | 19.09ms  |
| 99.000%    | 46.43ms  |
| 99.900%    | 70.53ms  |
| 99.990%    | 91.90ms  |
| 99.999%    | 98.11ms  |
| 100.000%   | 100.67ms |

На трех девятках ситуация плачевная. Адекватной работы удалось добиться
на 50к RPS, вывод wrk прикреплен. В приципе, падение производительности по сравнению
с PUT - запросами ожидаемо - ходить по
табличкам на диске дорого. Можно использовать фильтр Блума, чтобы немного поправить ситуацию,
и хотя бы не делать лишние бин. поиски.

На профилях работа равномерно распределена по потокам, львиная доля
ресурсов процессора все также уходит на бин. поиск.

Аналогично, сравним с предыдущим этапом: вывод для 25к RPS

| Percentile | time     |
|------------|----------|
| 50.000%    | 2.48ms   |
| 75.000%    | 6.09ms   |
| 90.000%    | 13.12ms  |
| 99.000%    | 99.01ms  |
| 99.900%    | 227.71ms |
| 99.990%    | 270.08ms |
| 99.999%    | 275.20ms |
| 100.000%   | 275.71ms |

Ситуация чуть лучше, чем с PUT, но все равно плохо.

Заметим, что latency всё равно увеличилась на больших перцентилях,
это может быть связано с тем, что в очереди в какой-то момент
лежало много запросов, и часть из них что попала в конец долго
ждала своей очереди.

## UPD: stack instead of queue

А что если использовать стэк, и сначала отвечать на свежие запросы?

### PUT

80k RPS

| Percentile | time     |
|------------|----------|
| 50.000%    | 1.30ms   |
| 75.000%    | 1.92ms   |
| 90.000%    | 2.82ms   |
| 99.000%    | 18.85ms  |
| 99.900%    | 66.05ms  |
| 99.990%    | 123.20ms |
| 99.999%    | 159.62ms |
| 100.000%   | 177.92ms |

По сравнению с ArrayBlockingQueue, latency упала в 2 раза на
90%, осталась почти такой же на 99% а вот на трех девятках уже
почти в два раза выше (сотый перцентиль вообще увеличился больше
чем в 3 раза). Да, мы выигрываем на основной массе запросов, но
часть из них может очень долго находиться на дне стека.
Так ли это критично? Наверное нет, все таки свежие запросы наверняка
актуальнее старых.

### GET

50k RPS

| Percentile | time     |
|------------|----------|
| 50.000%    | 2.14ms   |
| 75.000%    | 8.09ms   |
| 90.000%    | 16.82ms  |
| 99.000%    | 40.26ms  |
| 99.900%    | 62.14ms  |
| 99.990%    | 80.13ms  |
| 99.999%    | 97.28ms  |
| 100.000%   | 105.86ms |

Вот тут уже точно овчинка выделки не стоит, Latency сравнима с 65k RPS
на ArrayBlockingQueue. Почему так происходит? Если сравнивать профили,
заметную разницу можно увидеть только на lock-профиле.

[stack get lock profile](./asprof/stack_lock.html)

Блокировка на LinkedBlockingDeque.offer представлена в разы большим количеством
сэмплов, чем на ArrayBlockingQueue.offer. Непонятно, с чем это может быть
связано, и там и там используется один lock на чтение и запись.

Похоже, разумно будет остановить свой выбор на ArrayBlockingQueue.