# Отчёт о нагрузочном тестировании
## Этап 1

* Тестирование производилось при 10.000 RPS(GET) и 10.000 RPS(PUT) на 4 потока с одним 64 соединяниями.
* flushThresholdBytes 10Mb
* База заполнена на 65 Mb всеми ключами от 0 до 100000.
* Уменьшил число выделений в памяти для чтения после первого этапа
* Обработкой запросов занимется ThreadPoolExecutor с очередью на 100000 задач, 
пулом от 4 до 12 потоков
* Для тестирования была использована утилита wrk2.
* Для профилирования был использован async-profiler внутри IntelliJ IDEA


### Скрипты
* [get.lua](../scripts/get.lua)
* [put.lua](../scripts/put.lua)

### Результаты
[Вывод wrk2 для GET](get.txt)

[Вывод wrk2 для PUT](put.txt)

![](Histogram.png)

### Сравнение с прошлым этапом

[Вывод wrk2 для GET при одном соединении 4000RPS](getOneConnect.txt)
[Вывод wrk2 для GET при двух соединениях 4000RPS](getTwoConnects.txt)

При одном подключении со стороны клиента реализация работает значительно хуже,
много времени уходит синхронизацию очереди между потоками. Уже при двух соединяниях
эффективность значительно выше

### Стек вместо очереди

[wrk2 для стека](getStack.txt)

Для усорения большинства запросов в ущерб медленному меньшенству
используется стэк вместо очереди в ThreadPoolExecutor. Заметно небольшое ускорение
на больших процентилях.

#### Флеймграфы для GET запросов
##### CPU
![](getCpu.png)

##### Allocations
![](getMemory.png)


#### Флеймграфы для PUT запросов
##### CPU
![](putCpu.png)

##### Allocations
![](putMemory.png)

### Вывод
Удалось увеличить RPS по сравнению с прошлым этапом (при нескольких подключениях).
Большую часть времени и памяти всё так же потребляет http сервер.
Есть очевидная проблема с PUT, т.к. он работает медленнее GET, что по логике LSM должно быть наоборот;
предположительно из-за неэффективного копирования данных при flush.
Заметил, что текущий алгоритм компакшена небезопасен т.к. читает в память все данные.


