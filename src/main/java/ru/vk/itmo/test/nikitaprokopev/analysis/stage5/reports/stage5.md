## Значения переменных
* Размер очереди `500`
* Размер кластера `3`
* flushThreshold `1 Мб`
* потоков в каждом workerPool `8`

Прогрев ноды, запускаем нагрузку put запросов, потом сразу же запускаем нагрузку get.

## Тест 1 - кворум 2/3
Далее пробуем нагружать сервер предельными значениями Rps из прошлого этапа.
Проведя эксперименты оказалось, что сервис не справляется со старыми Rps и предельной нагрузкой(точкой разладки) для него является:
* `3800` запросов для put (было `3500`) - было 11 ms и отклонение 24 ms -> стало 21 ms и отклоненеи 23 ms
* `4300` запросов для get (было `3500`) - было 10 ms и отклонение 32 ms -> стало 26 ms и отклонение 29 ms


## Тест 2 - ack 1, from 3
Изменим ack на 1, from на 3 в скриптах wrk и проведем такие же замеры.
* `4500` запросов для put (было `3500`) - было 47 ms и отклонение 93 ms -> стало 18 ms и отклоненеи 36 ms
* `5500` запросов для get (было `3500`) - было 127 ms и отклонение 158 ms -> стало 7 ms и отклоненеи 18 ms

## Тест 3 - ack 3, from 3
* `3750` запросов для put (было `3500`) - было 10 ms и отклонение 22 ms -> стало 9 ms и отклоненеи 10 ms
* `3750` запросов для get (было `3500`) - было 35 ms и отклонение 54 ms -> стало 24 ms и отклоненеи 26 ms

Тестирование с увеличением числа нод приводить не стал, так как проводил это сравнение и в прошлом этапе и производительность сильно уменьшилась, так как мы работаем в рамках одной машины.

`RPS` увеличился, так как теперь все запросы отправляются паралелльно и не ждут друг друга. Значительное увеличение произошло при ack=1 и from=3, так как при первом успешном ответе отправляется ответ клиенту, не ожидая выполнения всех запросов.
То есть чем меньше ack тем быстрее клиент получит ответ. 
`latency` уменьшилась, так как мы уменьшили время ожидания ответа от сервера, за счет того что запросы параллельны и не ожидаем всех запросов, а отвечаем при достижении ack усепешных ответов.

## Профилирование

## GET

Особых изменений нет, кроме:
- CPU: появился класс CompletableFuture, который занимает 12% sample, которые "перетекли" из моего пула потоков.
- ALLOC: появился класс CompletableFuture, который занимает 30% sample, которые "перетекли" из моего пула потоков.
- LOCK: 30% занимают локи на обработке CompletableFuture

## PUT

Особых изменений нет, кроме:
- CPU: появился класс CompletableFuture, который занимает 13% sample, которые "перетекли" из моего пула потоков.
- ALLOC: появился класс CompletableFuture, который занимает 33% sample, которые "перетекли" из моего пула потоков.
- LOCK: 37% занимают локи на обработке CompletableFuture


## Выводы

При использовании CompletableFuture, мы увеличили немного производительность в случае использования ack < from и уменьшили latency, так как запросы отправляются параллельно и не ждут друг друга.

