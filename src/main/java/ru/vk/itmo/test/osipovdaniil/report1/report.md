# Отчёт по 1 заданию.

Скрипты для теста методов лежат в папке [scripts](../scripts) . 
Последовательные `put, get, delete`. <br>
`flushThresholdBytes = 2^20`<br>
Реализация `Dao` взята с референса.

## wrk2

Собственно сразу пошёл искать точку разладки запуская с помощью wrk2 скрипты 
[get](../scripts/get.lua)
и [put](../scripts/put.lua) .
с разным количеством запросов в секунду. <br>
Так я пришёл начиная с
[10000](wrk/put:1)
к константе
[13100](wrk/put:409) (когда пациент скорее жив, чем мертв, 1s на 90% персентилях)
запросов в секунду (между ними соответсвенно сам поиск и изменения задержек). `mean latency` было меньше секунды.
<br> Соответственно тестировать буду на 10000.

Однако решив перетестировать, заметил увеличение таймингов. <br>
Так обнаружил несколько зависимостей:
1) Скорость работы как `put` так и `get` падает с увеличением количевства SSTable'ов.
[Последовательный put](wrk/put:409)
2) `get` `delete` `get`. В такой последовательности второй `get` работает быстрее первого. <br>
Так же как 2-ой [delete](wrk/delete:93) после
[первого](wrk/delete:1). <br>
Логично ведь обновлённые данные лежат выше. Однако стоит отметить, что внутри все скрипты линейные.

Это было подтверждено, после сброса данных, вызовом скриптов в соотетсвующих последовательностях. <br>
Также было замечен стабильный
[значитальный](pictures/percentiles.html)
скачёк задержек 90 персентиле. 
Как будто происходит накопление нагрузки.

## async-profiler

Результаты в папке
[asyncprof](asyncprof)
<br>

С точки зрения cpu основные ресурсы съедает обработка запроса.
А именно функции `Dao` - `get, upsert, delete`.
Однако есть концептуальная разница в распределнии, так 
[get](asyncprof/get cpu.html)
съедает больше значительно больше ресурсов за счёт поиска и возвращения результата. Всё же есть бинпоиск.
В то время как 
[put](asyncprof/put alloc.html)
и [delete](asyncprof/delete cpu.html)
сама обработка запроса съедает мало ресурсов, так как новые записи кладутся на верх. Однако появляется графа связанная
с вызвом метода `flush`. <br>
Всё остальное это доп нагрузки на исполнение треда и исполнение функций библиотеки `one-nio`. 
В том числе `SelectorThread` (эти нагрузки можно будет с оптимизировать). 

С точки зрения аллокаций, распределение схожее, за исключением детали, что
в случае `put` и `delete` память аллоцируется на запись, 
а в случае `get` на возвращения результата 
