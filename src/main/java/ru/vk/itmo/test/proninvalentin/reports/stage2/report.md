## Put 30K RPS, 8 каналов

Первым делом сравним версию без пула и с ним.

Начнем с 30K запросов в 8 соединений, поскольку в one-nio по дефолту количество Selector Thread'ов равно количеству
ядер, в моем случае это число равно 8.

Также 30К запросов было объемом запросов, который мог выдержать наш сервер без пула.

### Перцентили в версии с пулом:

```
 50.000%    0.93ms
 75.000%    1.31ms
 90.000%    1.69ms
 99.000%    6.29ms
 99.900%   11.21ms
 99.990%   17.97ms
 99.999%   21.44ms
100.000%   22.02ms
```

### Перцентили в версии без пула:

```
50.000%  628.00us
75.000%    0.93ms
90.000%    1.11ms
99.000%    8.65ms
99.900%   35.13ms
99.990%   62.40ms
99.999%   65.09ms
100.000%   65.38ms
```

Видим разницу в задержке.
В версии с пулом нашему Selector потоку теперь не нужно тратить свои ресурсы на логику обработки запросов,
вместо этого он теперь может сразу заняться обработкой следующего запроса.

### CPU Flame Graph with Threads

![profile-cpu-many-threads-put-30000-1t-8c.png](aprof%2Fput%2Fprofile-put-30000-1t-8c%2Fprofile-cpu-many-threads-put-30000-1t-8c.png)
Поскольку диаграмма с отображением работы каждого треда нечитабельна, было решено отобразить график Worker и Selector
потоков отдельно.
При этом уже можно заметить, что количество Selector потоков, как я и говорил раньше, будет равно количеству ядер (8).

### Selector thread CPU Flame Graph

![selector-cpu-thread-put.png](aprof%2Fput%2Fprofile-put-30000-1t-8c%2Fselector-cpu-thread-put.png)

На графике с применением пула можно заметить, что Selector потоки теперь занимаются поллингом входящих запросов, чтением
запросов и отправкой запросов в пул воркерам (сюда же можно добавить взятие и освобождение блокировку на работу с
пулом).

### Worker thread CPU Flame Graph

![worker-cpu-thread-put.png](aprof%2Fput%2Fprofile-put-30000-1t-8c%2Fworker-cpu-thread-put.png)

Сами же воркеры занимаются чтением из очереди и ожиданием задач (это занимает львиную долю их работы, полагаю, что это
из-за недостаточного количества самих задач - воркеры попросту стоят без дела), выполнением логики работы с запросом
также часть времени уходит на
получение блокировки для работы с очередью.

В остальное время воркеры занимаются вставкой данных в бд, а также записью ответов в сокет (раньше этим занимались
Selector треды, тратя ~20% общего времени)

Для сравнения разницы по времени работы операций с версией без пула взглянем на CPU Graph без разделения на потоки.

### CPU Flame Graph

![profile-cpu-put-30000-1t-8c.png](aprof%2Fput%2Fprofile-put-30000-1t-8c%2Fprofile-cpu-put-30000-1t-8c.png)

| Работа селектора          | C пулом | Без пула | Объяснение (если нужно)                                                                                                                    |
|---------------------------|---------|----------|--------------------------------------------------------------------------------------------------------------------------------------------|
| Время работы селекторов   | 56%     | 100%     | -                                                                                                                                          |
| Поллинг запросов          | 40%     | 27%      | Теперь селектору в версии с пулом можно больше времени тратить на поллинг и скедулинг запросов, т.к. воркер треды забрали часть его работы |
| Обработка запроса         | 15%     | 56%      | В версии с пулом нам нужно лишь распарсить запрос и поставить его в очередь, не выполняя логику обработки запроса                          |
| Выполнение самого запроса | 1.5%    | 7%       | 1.5% в версии с пулом занимает постановка в очередь, когда в версии без пула селектор сам обрабатывает запрос                              |

В версии без пула этим занимается Selector поток

| Работа воркера        | C пулом | Без пула | Объяснение (если нужно)                                                                                                           |
|-----------------------|---------|----------|-----------------------------------------------------------------------------------------------------------------------------------|
| Время работы воркеров | 40%     | -        | -                                                                                                                                 |
| Ожидание задачи       | 25%     | -        | Мы испытываем версию с пулом не загрузив ее по максимуму<br/>Поэтому четверть от общего времени занимает ожидание задач воркерами |
| Обработка запроса     | 12%     | 56%      | Без пула обработка запроса полностью приходится на селектор                                                                       |
| Вставить данные в бд  | 1.65%   | 7%       | Для версии без пула, этот ряд совпадает с рядом "Выполнение самого запроса" из таблицы выше                                       |
| Отправка ответа       | 9.37%   | 19.53%   | В версии с пулом, отправкой ответа занимается воркер тред, а не селектор                                                          |

Можно заметить, что при добавлении пула мы очень сильно разгружаем наши селектор потоки, однако платим за это временем
на работу с самим пулом, хоть оно и незначительно

### ALLOC Flame Graph

| Операция                            | C пулом | Без пула | Объяснение (если нужно)                                                                                                                         |
|-------------------------------------|---------|----------|-------------------------------------------------------------------------------------------------------------------------------------------------|
| Запуск воркеров                     | 52%     | -        | -                                                                                                                                               |
| Обработка нового запроса селектором | 40%     | 87%      | Версия с пулом занимается только парсингом запроса, <br/>тогда как версия без пула занимается еще и выполнением логики обработки самого запроса |
| Вставка в бд                        | 29%     | 26%      | -                                                                                                                                               |
| Формирование ответа                 | 11%     | 10%      | -                                                                                                                                               |
| Взять задачу из очереди             | 3%      | -        | -                                                                                                                                               |
| Запуск селекторов                   | 47.7%   | 94%      | В версии с пулом половина общей памяти уходит также на создание воркеров                                                                        |
| Select нового запроса               | 7%      | 6.5%     | -                                                                                                                                               |

В некоторых случаях соотношение по выделению изменилось в ~2 раза, т.к. добавились затраты на накладные расходные для работы с
воркерами и их создание

## PUT 70K RPS, 1024 channel:

Как и в предыдущем этапе, определим точку разладки, начнем с 70К RPS в 1024 каналов, т.е. теперь 1024 запросов могут одновременно попасть к нам на сервер

### Перцентили:

```
50.000%    1.01ms
75.000%    1.35ms
90.000%    1.64ms
99.000%    2.28ms
99.900%    9.30ms
99.990%   16.69ms
99.999%   21.17ms
100.000%   24.56ms
```

Перцентили показывают довольно радостную картинку, которую объясняют следующие строки:
```
Socket errors: connect 781, read 0, write 0, timeout 46079
Requests/sec:  16601.94
```

Т.е. мы видим, что настоящая нагрузка составляла всего 16К RPS и наш сервер смог одновременно обработать только `1024-781=243` соединений

Я связываю это с тем, что 8 селекторов просто не успевают опрашивать такое количество соединений, учитывая тот факт, что работа с соединениями не кратковременная, т.к. пишем мы в них постоянно.

### CPU Flame Graph

![profile-cpu-put-70000-8t-1024c.png](aprof%2Fput%2Fprofile-put-70000-8t-1024c%2Fprofile-cpu-put-70000-8t-1024c.png)

### Alloc Flame Graph

![profile-alloc-put-70000-8t-1024c.png](aprof%2Fput%2Fprofile-put-70000-8t-1024c%2Fprofile-alloc-put-70000-8t-1024c.png)

Профили также не показывает особых аномалий, т.е. сервер просто не принимал больше соединений

## PUT 70K RPS, 256 channel:

При уменьшении до 256 одновременных соединений можно увидеть, что количество ошибок также снизилось, но недостаточно
```
  7968590 requests in 2.00m, 509.16MB read
  Socket errors: connect 13, read 0, write 0, timeout 767
```

## PUT 70K RPS, 200 channel:

При уменьшении до 200 одновременных соединений ошибки пропали


### Перцентили:
```
50.000%    1.28ms
75.000%    1.75ms
90.000%    2.27ms
99.000%    3.45ms
99.900%   23.44ms
99.990%   61.53ms
99.999%   74.24ms
100.000%   81.15ms
```

На 99.9+ перцентилях можно заметить возрастание задержки, связываю это с тем, что чаще срабатывала сборка мусора и, в целом, это больше похоже на артефакты, тк профили показывают аналогичную с предыдущими запусками картину

### CPU Flame Graph
![profile-cpu-put-70000-8t-200c.png](aprof%2Fput%2Fprofile-put-70000-8t-200c%2Fprofile-cpu-put-70000-8t-200c.png)

Больше времени начало уходить на ожидание работы с очередью при взятии и добавлении задачи, в остальном, графики аналогичны

### Alloc Flame Graph
![profile-alloc-put-70000-8t-200c.png](aprof%2Fput%2Fprofile-put-70000-8t-200c%2Fprofile-alloc-put-70000-8t-200c.png)

Профиль аллокаций также особо не поменялся

### Lock Flame Graph
![profile-lock-put-70000-8t-200c.png](aprof%2Fput%2Fprofile-put-70000-8t-200c%2Fprofile-lock-put-70000-8t-200c.png)

По профилю блокировок можно увидеть, что основное время ходит на взятие блокировки при взятии задачи из пула и ее добавлении туда.

Лишь 2.5% уходит на то, чтобы взять блокировку для записи в сессию

## Улучшения

В качестве возможных улучшений мы можем поиграть со следующими параметрами:
* Размер пула - лучше выставить сразу в количество ядер начальное и максимальное значение, чтобы после появления нагрузки не тратить ресурсы на выделение новых потоков. 
Кроме этого, также можно выставить это значение выше количества ядер в нашей системе, если жесткий диск, с которым идет работа, поддерживает NVME.
Поскольку сам NVME поддерживает параллельность потоков.
* Максимальный размер очереди - слишком большая очередь будет позволять храниться долгим запросам, слишком короткая может не справиться с большим количеством одновременных запросов.
* Максимальное время обработки запроса - зависит от SLA предъявляемых вашему сервису. В своей реализации я добавил игнорирование запросов, у которых истек таймаут (сейчас стоит 200 мс). На такие запросы клиенту отправляется ответ "408 Request Timeout".

Также можно поменять тип очереди, который мы используем в пуле:

* LinkedBlockingDeque - LIFO, интересный вариант, т.к. позволяет нам акцентировать внимание сервера на новых запросах
* ArrayBlockingQueue - FIFO, я считаю этот вариант предпочтительнее, т.к. при нем не возникает ситуации, когда старые запросы улетают в самый конец обработки очереди при большой нагрузке

Но, конечно, выбирать стоит `PriorityBlockingQueue` вкупе с ошибкой 'Payment required' для самых медленных запросов (шутка с лекции)

Также можно выбрать политику обработки запросов при заполнении очереди:
* AbortPolicy кидает исключение, которое мы можем обработать, чтобы оповестить наших клиентов о перегрузке сервера
* DiscardPolicies определяет какие запросы мы будем выкидывать из очереди - новые или старые. 
В нашем случае это неподходящая политика, т.к. при ней клиент не узнает о том почему его запрос не выполнился и при мониторинга сервера мы также этого не увидим 
* CallerRunsPolicy позволяет потоку, который добавил задачу в очередь самостоятельно распорядиться тем как обработать ситуацию при переполнении очереди. Нам данная политика не подходит по причине того, что мы не хотим нагружать наш Selector поток дополнительными задачами.