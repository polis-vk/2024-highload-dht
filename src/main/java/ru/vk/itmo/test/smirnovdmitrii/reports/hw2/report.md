# Отчет по HW2

## Как все выглядит до

Сначала посмотрим, как работает сервер до включения асинхронной работы, чтобы улучшения были совсем наглядные.

На этом этапе я вынес все в `property` файл, поэтому отключение воркеров можно сделать одним флагом.

Для удобства работы был написал скрипт на питоне, который сохраняет результаты и выводит графики в каком-то результате,
который все-таки хуже чем гистограммы на сайте, поэтому не слишком нужны в дальнейшем.

[результаты последовательного put до включения асинхронной работы](sync/put1)

[результаты случайного get до включения асинхронной работы](sync/get1)

Для начала нужно заметить, что в 100 соединений сервер просто отказывается работать, а `wrk` не выдает никаких результатов.

Итого точка разладки:
- Для последовательного `put` около 40k rps
- Для случайного `get` около 30k rps.

## Async

Посмотрим, как работает сервер, если `SelectorThread` будет создавать задания, а не идти в базу.

Настройки:
- Минимальное количество `workers`: 2
- Максимальное количество `workers`: 128
- Тип очереди: `ArrayBlockingQueue`
- Длина очереди: `100`
- Количество `SelectorThreads`: 10 (столько же ядер на машине)
- Количество соединения: 128 (столько же, сколько и потоков)

[результаты последовательного put при асинхронной работе](async/connections/put_connect128)

[результаты случайного get при асинхронной работе](async/connections/get_connect128)

Для такой настройки точка разладки вышла:
- Для `put` около 65k rps
- Для `get` около 48k rps.

То есть результаты уже вышли в 1,5 раза лучше.

Теперь можно поэкспериментировать с параметрами!

#### Connections

Для начала посмотрим, как будет влиять количество connectов. Обжевывать каждый из нагрузочных тестов я не буду, но приведу общую картнку.

![get graphics](https://disk.yandex.ru/i/YagHr97P0MrRCw)

![put graphics](https://disk.yandex.ru/i/mM-gwYjNRW6djQ)

По графикам отлично видно, что делать connectionов сильно больше, чем тредов приводит к печальным последствиям.

Объяснить для себя при маленьком количестве conneсtionов улучшение работы же я могу различными способами.

#### Очереди (и пломбир за 48 копеек)

Я был немного в шоке, но оно работало, причем хорошо.

Мы заставляли каждый из пришедших `SelectorThread` ждать, пока `Worker` заберет его таску и он дожидался.

Графики сравнения работ при разных очередях.

[get](https://disk.yandex.ru/i/ngNgIIELtXs6Mg)

[put](https://disk.yandex.ru/i/8c-579AyOF9-kw)

Не даром эта очередь стоит по дефолту в `one-nio`.

Двигая границу, я смог поднять rps в get до 60к!
[результаты](async/queue/get_sync_queue2)

Но внутри я знаю, что лучшая структура данных это массив, а значит
`ArrayBlockingQueue` должна быть быстрее.

В итоге длина очереди 128 (столько же, сколько и потоков) смогла выдать:
- 54к rps на `get`
- 67k rps на `put`

Почему-то get стал быстрее, чем put. Возможно, проблема в тестах и данных стало больше кэшироваться, но выяснить это я не смог.

### Virtual Threads

Виртуальные потоки на той же нагрузке справились хуже
[виртуальные потоки на get](vthreads/get_vthreads)

[виртуальные потоки на put](vthreads/put_vthreads)


### Профилирование

Профилирование происходило при полученной нагрузке `get` и `put` в конце прошлого пункта.

#### CPU

Виртуальные потоки в итоге отдавали 30+ процентов CPU на переключение между собой.

[Картинка для put](https://disk.yandex.ru/i/bOSwEtWIrO49xA)


На 128 потоках система показала такой профиль

[Картинка для cpu get](https://disk.yandex.ru/i/dV-MShbY7coAWQ)

[Картинка для alloc get](https://disk.yandex.ru/i/JNEECTKDYk6Tzg)

[Картинка для lock get](https://disk.yandex.ru/i/unaT948z4yDDlQ)

[Картинка для cpu put](https://disk.yandex.ru/i/BICMR-htfoAKyw)

[Картинка для alloc put](https://disk.yandex.ru/i/KjdQpXosrpdUEw)

[Картинка для lock put](https://disk.yandex.ru/i/SmdBIWIlOnapVA)

Что там интересного? Профиль блокировок для get и put должны отличаться ведь внутри, но
 отличаются не так, как я предполагал. Почему-то мы имеем две разные блокировки внутри `ThreadPoolExecutorа` для put. А также
на профиле не видно, как поток для `flush` ждет блокировок read-write лока (только он должен был ждать внутри Dao).

Также удивила ситуация по alloc. Если put почти не генерирует ресурсов, то get из-за бинарного поиска генерирует каждый раз новые `MemorySegment`.
Из-за этого используется __неприлично__ много памяти, когда как get запрос принимает только ключ.
