## Начальные сведения 
* Виртуалке были даны 2 ядра (будем надеяться, что не помрет)
* Конфигурация кластера: 3 ноды
* Реплицирование по умолчанию (2/3)

## PUT 30000 30s 4 threads 64 con

Сначала попробуем найти новую точку разладки. Сравнивая входные данные с прошлого этапа, что почему-то больше 1 потока
и 1 соединения не проходило, количество запросов упало до 3000-5000. В этот раз мало что изменилось. По входных данным
4 потока и 64 соединения результаты в [put-profile-4th-64con-30000.txt](put-profile-4th-64con-30000.txt). Очень мало
запросов в приципе успевают обработаться и большинство ловят TimeOut.

```
 50.000%   20.07s
 75.000%   24.92s
 90.000%   27.93s
 99.000%   29.74s
 99.900%   29.77s
 99.990%   29.77s
 99.999%   29.77s
100.000%   29.77s
```

## PUT 3000 30s 1 thread 1 con

Тогда вернемся к работающим входным данным прошлого этапа. Результаты эксперимента в сравнении с прошлым этапом при
1 поток, 1 соединение, 3000 запросов приведены ниже.

```
            было        стало
 50.000%   19.32s       21.04s
 75.000%   23.40s       24.48s
 90.000%   26.05s       25.85s
 99.000%   27.61s       27.34s
 99.900%   27.69s       27.46s
 99.990%   27.71s       27.48s
 99.999%   27.71s       27.48s
100.000%   27.71s       27.48s 
```

На 50-ом перцентиле время выросло, на других в прицнипе не изменилось. Также можно отметить, что по результатам
подобного эксперимента на прошлом этапе и на этом меньше половины запросов успевают обработаться.

При времени 30 секунд и 3000 запросов результат: 7576 requests in 30.00s, 495.70KB read. Я все же предполагаю, что это
из-за предоставленных виртуалке ресурсов.

Также стоит отметить, что при добавлении пересылки по сети из-за наличия реплицирования, время обработки должно
было увеличиться. Однако об этом сложно судить при таких результатах эксперимента.

## CPU

[put-profile-1th-cpu.html](put-profile-1th-cpu.html)

В сравнении с прошлым этапом ситуация особым образом не поменялась. Все также тратиться время на отправку ответа
клиенту и ожидание ответа от других нод. Еще также сама обработка логики. Больше всего времени остается за операцией
Unsafe.park (3.34%), которая, как я понимаю, и занимается блокировкой и ожиданием потока.

Так как в этом этапе происходила работа с хэдерами запросом (0.30%), теперь они также отражаются на фрейм-графах.

В другой нагрузке:
- ThreadPoolExecutor.runWorker: с 24.07% до 46.93% увеличилось. Работа с запросами происходит в основном в ворекерах,
соответсвенно и увеличилась нагрузка.
- HttpClientImpl$SelectorManager.run: с 11.14% до 20.10% увеличилось. Предположение: из-за работы с http-запросами.
- ThreadPoolExecutor.getTask: с 9.30% до 16.70% увеличилось

## ALLOC

[put-profile-1th-alloc.html](put-profile-1th-alloc.html)

По аллокациям ситуация с прошлым этапом особо не отличается. Отличается только расходование ресерсов у некоторых 
семплов. Странно, что Server.processingRequest стал меньше потреблять: с 26.43% уменьшилось до 24.65%. Также еще ресурсы
расходуются на построение http запросов к нескольким узлам сразу.

## LOCK

[put-profile-1th-lock.html](put-profile-1th-lock.html)

- HttpClientImpl$SelectorManager.run: с 64.47% уменьшилось до 50.74%. Хотя запросов стало больше.
- ThreadPoolExecutor.runWorker: с 2.16% до 3.25% увеличилось. Все ресурсы уходят на HttpSession.sendResponse.

## GET 5000 30s 1 thread 1 con

Аналогично как и с запросами PUT было решение попробовать при тех же входных данных, как в прошлом этапе, то есть 
1 соединение, 1 поток, 5000 запросов. Результаты перцентилей приведены ниже.

```
            было        стало
 50.000%   19.55s       19.96s
 75.000%   23.79s       24.76s
 90.000%   25.85s       27.25s
 99.000%   27.34s       28.48s
 99.900%   27.46s       28.56s
 99.990%   27.46s       28.57s
 99.999%   27.46s       28.57s
100.000%   27.46s       28.57s
```

Видно, что время вырасло на секунды. Но предполагая также как и с PUT-запросами сложно судить, произошло это из-за
наличия реплицирования или из-за ресурсов виртуалки.

## CPU

[get-profile-1th-cpu.html](get-profile-1th-cpu.html)

- ThreadPoolExecutor.runWorker: с 20.85% до 19.68% уменьшилось. 
- HttpClientImpl$SelectorManager.run: с 16.62% до 19.92% увеличилось.
- ThreadPoolExecutor.getTask: с 14.26% до 17.16% увеличилось.
- Server.processingRequest: с 17.40% до 15.90% уменьшилось. Тоже немного странно, что уменьшилось, когда количество
работы наоборот увеиличилось.

## ALLOC

[get-profile-1th-alloc.html](get-profile-1th-alloc.html)

- HttpClientImpl$SelectorManager.run: на предудыщем этапе его вообще не было видно, на графе этого этапа 6.43%.
Должно было увелиться, так как при рабое с клиентом появляются дополниельные аллокации.
- Server.processingRequest: тоже на предыдущих не было видно, на графе этого этапа 28.55%. Аналогично, что должно быть
увеличение, так как работа с клиентом, парсинг ответов и т.д.

## LOCK

[get-profile-1th-lock.html](get-profile-1th-lock.html)

- HttpClientImpl$SelectorManager.run: с 44.61% уменьшилось до 44.01%. Также странно, как и при PUT-запросах.
- ThreadPoolExecutor.runWorker: с 11.76% до 4.61% уменьшилось.

## Выводы

- Сложно делать какие-то конкретные выводы ввиду непонимая причин плохих показателей у wrk, но предположение, что из-за
репликации произошли ухудшения, можно вынести. Но само хранение данных стало более надежным из-за наличия реплик.
- Также плюсом является то, что можно указать необходимое количество узлов для запроса. Так можно лавировать между
скоростью на запись и скоростью на чтение.

## Улучшения

- Добавление асинхронности к клиенту, чтоб слать запросы параллельно. При том, что есть параметры from и ack, можно
дождаться ответа только от ack узлов.

P.S. Спасибо большое виртуалке, что за время написания отчета и проведения экспериментов она ниразу не умерла.