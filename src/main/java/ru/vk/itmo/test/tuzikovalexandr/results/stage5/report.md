## Начальные сведения
* Виртуалке были даны 4 ядра (будем надеяться, что не помрет)
* Конфигурация кластера: 3 ноды
* Реплицирование по умолчанию (2/3)

## PUT 5000 30s 1 thread 2 con

Работающие входные данные остаются с прошлого этапа. Результаты эксперимента в сравнении с прошлым этапом при
1 поток, 2 соединение, 5000 запросов приведены ниже. [put-profile-1th-2con-5000.txt](put-profile-1th-2con-5000.txt)

```
            было        стало
 50.000%    5.12s       17.25s
 75.000%    7.24s       21.48s
 90.000%    7.24s       23.95s
 99.000%    8.55s       25.41s
 99.900%    9.33s       25.53s
 99.990%    9.33s       25.53s
 99.999%    9.33s       25.54s
100.000%    9.33s       25.54s
```

Результаты получились не те, которые ожидались. Время обработки вырасло почти в 3 раза.
Но по результатам другого эксперимента, когда входные данные 1 поток, 2 соединение, 10000. Время начинает уменьшаться.
Результаты в файле [put-profile-1th-2con-10000.txt](put-profile-1th-2con-10000.txt).

Отмечу еще, что при увеличении количества соединений возникали проблемы с тестированием. Все улетало в таймаут.

## CPU

[put-profile-1th-cpu.html](put-profile-1th-cpu.html)

- Добавился ForkJoinWorkerThread.run 16.40%;
- Изменились пропорции некоторые семплов.

Что-то координальных изменений я не выявил, за исключением того, что добавлась работа у воркеров с CompletableFuture.

## ALLOC

[put-profile-1th-alloc.html](put-profile-1th-alloc.html)

При работе с CompletableFuture появилась новая аллокация ForkJoinWorkerThread.run. 

При работе над 5 этапом я изменил ConsistentHashing. На профиле видно, что в сравнении с предыдущим этапом аллокаций
стало меньше. Но тут так получилось из-за базового количества ack и from. Получалось, что не срабатывал итератор. А
так аллокаций должно было быть даже больше.

В остальном ничего другого не заметил. Хотя, как мне казалось, должна была быть аллокация на дефолтный экзекьютор, так
как сам я их не создавал. Но этого не нашел.

## LOCK

[put-profile-1th-lock.html](put-profile-1th-lock.html)

- ThreadPoolExecutor.runWorker изменился 3.25% до 37.07%;
- ThreadPoolExecutor.getTask 1.98%. Вырос не так сильно;
- CompletableFuture$AsyncSupply.run 10.62%. На 3 этапе занимал всего 0.36%;
- SequentialScheduler$SchedulableTask.run занимает больше всего 21.07%. Вырос в сравнении с предыдущими этапами.
На 3 этапе было всего 0.58%.

Такие изменения связаны с тем, что добавилось много асинхронного работы.

## GET 5000 30s 1 thread 2 con

Аналогично, как и с PUT запросами входные данные остались те же, только количество соединений увеличил до 2. 
Однако, в отличии от PUT запросов время стало лучше.

```
            было        стало
 50.000%   19.96s       14.93s
 75.000%   24.76s       17.96s
 90.000%   27.25s       23.90s
 99.000%   28.48s       26.10s
 99.900%   28.56s       26.33s
 99.990%   28.57s       26.35s
 99.999%   28.57s       26.35s
100.000%   28.57s       26.35s
```

## CPU

[get-profile-1th-cpu.html](get-profile-1th-cpu.html)

Аналогично, как и в случае с PUT запросами. Только немного другие пропорции.

## ALLOC

[get-profile-1th-alloc.html](get-profile-1th-alloc.html)

Аналогично, как и в случае с PUT запросами в том числе и ConsistentHashing.

## LOCK

[get-profile-1th-lock.html](get-profile-1th-lock.html)

Аналогично, как и в случае с PUT запросами. Только немного другие пропорции.

## Выводы

- При добавлении логики асинхронной работы с CompletableFuture, соответсвенно выросла и трата ресуросв на работу с ними.
Соответсвенно, самыми показательными были LOCK фреймы.

## Улучшения

- Предложений нет.

P.S. Снова спасибо большое виртуалке, что за время написания отчета и проведения экспериментов она ниразу не умерла.